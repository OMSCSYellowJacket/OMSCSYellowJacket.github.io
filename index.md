# Scaling Machine Learning Applications: How to Create Robust Applications
## Introduction (Content Track)
Due to the current popularity of artificial intelligence, machine learning classes
at the elementary, secondary, and tertiary level have been increasing. Despite
the rise in the number of machine learning literate students, the capability to
operationalize such applications has been problematic. A disconnect exists between
the development of machine learning systems and the deployment of
said systems. One common complaint is that while most machine
learning engineers are capable of manipulating algorithms, developing
models, and creating crude prototypes, they lack the knowledge to implement
more sophisticated prototypes and production systems. The dynamics of machine learning systems differ from traditional rule-based
software systems. Data scientists need to have a system-centric mindset as
opposed to a model-centric mindset when dealing with such systems.
The disconnect between an expanding machine learning workforce and deploying
robust machine learning applications may suggest a disconnect between the
content of educational courses and the needs of industry. Specifically, machine learning is taught at a theoretical level with a focus primarily on
algorithm development. In cases where such educational content is developed,
it was focused on the data component of these systems, and executed with sanitized
data. This course will focused creating educational content on how to create end-to-end machine learning applications with high velocity market data using a project based learning approach.
This type of approach is based on experiential learning.

## Lessons

<b> Module 1: Streaming Data Fundamentals </b><br> 
- Introduction to Streaming Data
- Definition and characteristics of streaming data
- Differences between batch processing and stream processing
- Algorithms for real-time data processing
- Requirements engineering

<b> Module 2: Stream Processing Architectures</b><br> 
- Overview of kappa stream processing architecture
- Key components: data producers, consumers, and brokers
- Introduction to message brokers (e.g., Apache Kafka, RabbitMQ)
  
<b> Module 3: Streaming Data Frameworks</b><br> 
- Introduction to Apache Kafka
- Setting up Kafka and understanding its architecture
- Producing and consuming messages in Kafka
- Concepts of topics, partitions, and consumer groups
- Stream Processing with Apache Flink or Apache Spark Streaming
4
- Overview of Flink/Spark Streaming
- Processing streams: transformations, windowing, and aggregations
- Handling stateful processing and fault tolerance
  
<b> Module 4: Data Handling and Storage</b><br> 
- Real-Time Data Storage Solutions
- Overview of databases suitable for streaming data (e.g., Cassandra, Redis)
- Introduction to time-series databases (e.g., InfluxDB)
- Data modeling for streaming applications
- Designing ETL pipelines for real-time data ingestion
  
<b> Module 5: Building Data-Driven Applications</b><br> 
- Develop real-time application using market price data to create buy/sell signals

## Current Content

For Milestone one initial content has been developed and can be found at the link below.  This content will be organized for Milestone two. This content will culminated into a project for the final report.<br>

[Current Content](https://omscsyellowjacket.github.io/content)<br>
